{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bread</th>\n",
       "      <th>eggs</th>\n",
       "      <th>jam</th>\n",
       "      <th>milk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bread   eggs    jam   milk\n",
       "0   True   True  False   True\n",
       "1   True   True  False  False\n",
       "2   True  False  False   True\n",
       "3  False   True  False   True\n",
       "4   True   True   True   True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Sample dataset\n",
    "dataset = [['milk', 'bread', 'eggs'],\n",
    "           ['bread', 'eggs'],\n",
    "           ['milk', 'bread'],\n",
    "           ['milk', 'eggs'],\n",
    "           ['milk', 'bread', 'eggs', 'jam']]\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit_transform(dataset)  # Apply one-hot-encoding on our dataset\n",
    "df = pd.DataFrame(te_ary, columns = te.columns_)  # Creating a new DataFrame from our Numpy array\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PC\\Downloads\\Associative.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/Downloads/Associative.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlxtend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfrequent_patterns\u001b[39;00m \u001b[39mimport\u001b[39;00m apriori\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Downloads/Associative.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df1 \u001b[39m=\u001b[39m apriori(df, min_support \u001b[39m=\u001b[39m \u001b[39m0.6\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Downloads/Associative.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df1\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlxtend\\frequent_patterns\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Sebastian Raschka 2014-2023\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# mlxtend Machine Learning Library Extensions\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Author: Sebastian Raschka <sebastianraschka.com>\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# License: BSD 3 clause\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mapriori\u001b[39;00m \u001b[39mimport\u001b[39;00m apriori\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39massociation_rules\u001b[39;00m \u001b[39mimport\u001b[39;00m association_rules\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfpgrowth\u001b[39;00m \u001b[39mimport\u001b[39;00m fpgrowth\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlxtend\\frequent_patterns\\apriori.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfrequent_patterns\u001b[39;00m \u001b[39mimport\u001b[39;00m fpcommon \u001b[39mas\u001b[39;00m fpc\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_new_combinations\u001b[39m(old_combinations):\n\u001b[0;32m     14\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m    Generator of all combinations based on the last state of Apriori algorithm\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcollections\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdistutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m LooseVersion \u001b[39mas\u001b[39;00m Version\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "df1 = apriori(df, min_support = 0.6)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apriori' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PC\\Downloads\\Associative.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/Downloads/Associative.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m frequent_itemsets \u001b[39m=\u001b[39m apriori(df, min_support \u001b[39m=\u001b[39m \u001b[39m0.6\u001b[39m, use_colnames \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m#Instead of column indices we can use column names.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Downloads/Associative.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m frequent_itemsets \n",
      "\u001b[1;31mNameError\u001b[0m: name 'apriori' is not defined"
     ]
    }
   ],
   "source": [
    "frequent_itemsets = apriori(df, min_support = 0.6, use_colnames = True) #Instead of column indices we can use column names.\n",
    "frequent_itemsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "frequent_itemsets['length'] = df1['itemsets'].apply(lambda x : len(x))\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules \n",
    "rules_confidence = association_rules(frequent_itemsets, metric = 'confidence', min_threshold = 0.7) # associate items\n",
    "rules_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "rules_lift = association_rules(frequent_itemsets, metric = \"lift\", min_threshold = 0.75)\n",
    "rules_lift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***Frequent Item Sets***: These represent item combinations that occur frequently together in transactions.\n",
    "* ***Association Rules***: These are the discovered relationships between items, including metrics like support, confidence, and lift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "market = pd.read_csv('Market_Basket_Optimisation.csv')\n",
    "market.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Reshape the data to have all products in a single column\n",
    "\n",
    "market_transactions = []\n",
    "for index, row in market.iterrows():\n",
    "    transaction = [str(item) for item in row if pd.notna(item)]\n",
    "    market_transactions.append(transaction)\n",
    "\n",
    "# Convert the transactions to a DataFrame with a single column\n",
    "transaction_df = pd.DataFrame({'products': transactions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "transaction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Transform the data for Apriori algorithm using one-hot encoding\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)  #Apply one-hot-encoding on our dataset\n",
    "one_hot_df = pd.DataFrame(te_ary, columns = te.columns_)  #Creating a new DataFrame from our Numpy array\n",
    "one_hot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Applying Apriori algorithm\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "frequent_itemsets = apriori(one_hot_df, min_support = 0.01, use_colnames = True)\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "frequent_itemsets.sort_values(by = ['support'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Generate association rules\n",
    "\n",
    "rules_confidence = association_rules(frequent_itemsets, metric = 'confidence', min_threshold = 0.5)\n",
    "rules_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Generate association rules\n",
    "\n",
    "rules_lift = association_rules(frequent_itemsets, metric = 'lift', min_threshold = 1.0)\n",
    "rules_lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "rules_lift.sort_values(by = 'confidence', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good question: How do I know the exact value of minimum support, and the minimum thresholds for lift and confidence.\n",
    "\n",
    "Answer: Determining the values for minimum support, minimum threshold (for lift), and minimum threshold (for confidence) involves a balance between finding meaningful patterns without generating too many or too few rules. Here's how you might approach setting these parameters:\n",
    "\n",
    "### Minimum Support: \n",
    "\n",
    "* **Support** measures the frequency of an item set in the entire dataset.\n",
    "* Setting `min_spport` too low might result in too many frequent item sets, making it harder to extract meaningful patters.\n",
    "* Setting it too high might miss potentially interesting and useful item sets.\n",
    "* A commom approach is to start with a low support threshold like 1% or 5% and then adjust it based on the specific context or desired patterns.\n",
    "\n",
    "\n",
    "### Minimum Confidence:\n",
    "\n",
    "* **Confidence** measures the likelihood that a rule is true given the presence of another item set.\n",
    "* Setting `min_confidence` too low might result in too many rules, including many that are not very useful or meaningful.\n",
    "* Setting it too high might lead to missing potentially interesting associations.\n",
    "* A commonly used threshold for confidence is around 50% or higher, but this can vary based on the application and the context.\n",
    "\n",
    "\n",
    "### Minimum Lift:\n",
    "\n",
    "* **Lift** measures how much more likely one item set is to occur given the occurrence of another item set, compared to if their occurrences were independent.\n",
    "* Setting `min_lift` too low might result in including associations that are not particularly significant.\n",
    "* Setting it too high might filter out potentially useful associations.\n",
    "* There isn’t a universal threshold for lift, but values greater than 1 typically indicate a meaningful association (indicating the items are correlated).\n",
    "\n",
    "\n",
    "\n",
    "### Approach:\n",
    "\n",
    "* **Start Conservatively**: Begin with a higher `min_support` and `min_confidence` and gradually decrease them if you're not finding enough associations or patterns.\n",
    "* **Domain Knowledge**: Utilize your domain expertise or context-specific knowledge to identify potentially interesting item sets or associations.\n",
    "* **Iterative Process**: Adjust the parameters iteratively based on the patterns discovered and the insights needed.\n",
    "* **Balance**: Find a balance between generating too many rules (which might include noise) and missing important associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
